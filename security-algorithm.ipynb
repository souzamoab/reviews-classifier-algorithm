{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aplicativo melhorou n칩s 칰ltimos meses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>칍timo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>칍timo e muito pr치tico 游뗵游뗵</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aplicativo TOP, F치cil, e Pr치tico.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>estou adorando muito seguro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 comments\n",
       "0  Aplicativo melhorou n칩s 칰ltimos meses.\n",
       "1                                   칍timo\n",
       "2                칍timo e muito pr치tico 游뗵游뗵\n",
       "3       Aplicativo TOP, F치cil, e Pr치tico.\n",
       "4             estou adorando muito seguro"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_json('reviews.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aplicativo melhorou n칩s 칰ltimos meses.</td>\n",
       "      <td>aplicativo melhorou nos ultimos meses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>칍timo</td>\n",
       "      <td>otimo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>칍timo e muito pr치tico 游뗵游뗵</td>\n",
       "      <td>otimo e muito pratico 游뗵游뗵</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aplicativo TOP, F치cil, e Pr치tico.</td>\n",
       "      <td>aplicativo top, facil, e pratico.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>estou adorando muito seguro</td>\n",
       "      <td>estou adorando muito seguro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 comments  \\\n",
       "0  Aplicativo melhorou n칩s 칰ltimos meses.   \n",
       "1                                   칍timo   \n",
       "2                칍timo e muito pr치tico 游뗵游뗵   \n",
       "3       Aplicativo TOP, F치cil, e Pr치tico.   \n",
       "4             estou adorando muito seguro   \n",
       "\n",
       "                          cleaned_reviews  \n",
       "0  aplicativo melhorou nos ultimos meses.  \n",
       "1                                   otimo  \n",
       "2                otimo e muito pratico 游뗵游뗵  \n",
       "3       aplicativo top, facil, e pratico.  \n",
       "4             estou adorando muito seguro  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "import unicodedata\n",
    "\n",
    "def setup_abbr():\n",
    "    file = open(\"abbr_portuguese.txt\", encoding='utf-8')\n",
    "    abbr_dict = {}\n",
    "\n",
    "    for line in file:\n",
    "        w = line.split(\";\")\n",
    "        abbr_dict[w[0]] = w[1].replace(\"\\n\", \"\")\n",
    "    file.close()\n",
    "\n",
    "    return abbr_dict\n",
    "\n",
    "def clean(data):\n",
    "    doc = nlp(data)\n",
    "    doc_lower = doc.text.lower()\n",
    "    doc_punctuation = u\"\".join([c for c in unicodedata.normalize('NFKD', doc_lower) if not unicodedata.combining(c)])\n",
    "    doc_corrected = nlp(\" \".join([abbr_dict.get(w, w) for w in doc_punctuation.split()]))\n",
    "    \n",
    "    return doc_corrected.text\n",
    "\n",
    "nlp = spacy.load('pt_core_news_lg')\n",
    "abbr_dict = setup_abbr()\n",
    "\n",
    "data['cleaned_reviews'] = data['comments'].apply(clean)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/moabsouza/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/moabsouza/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/moabsouza/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "      <th>pos_tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aplicativo melhorou n칩s 칰ltimos meses.</td>\n",
       "      <td>aplicativo melhorou nos ultimos meses.</td>\n",
       "      <td>[(aplicativo, n), (melhorou, v), (ultimos, Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>칍timo</td>\n",
       "      <td>otimo</td>\n",
       "      <td>[(otimo, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>칍timo e muito pr치tico 游뗵游뗵</td>\n",
       "      <td>otimo e muito pratico 游뗵游뗵</td>\n",
       "      <td>[(otimo, None), (pratico, v), (游뗵游뗵, n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aplicativo TOP, F치cil, e Pr치tico.</td>\n",
       "      <td>aplicativo top, facil, e pratico.</td>\n",
       "      <td>[(aplicativo, n), (top, None), (,, None), (fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>estou adorando muito seguro</td>\n",
       "      <td>estou adorando muito seguro</td>\n",
       "      <td>[(adorando, v), (seguro, n)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 comments  \\\n",
       "0  Aplicativo melhorou n칩s 칰ltimos meses.   \n",
       "1                                   칍timo   \n",
       "2                칍timo e muito pr치tico 游뗵游뗵   \n",
       "3       Aplicativo TOP, F치cil, e Pr치tico.   \n",
       "4             estou adorando muito seguro   \n",
       "\n",
       "                          cleaned_reviews  \\\n",
       "0  aplicativo melhorou nos ultimos meses.   \n",
       "1                                   otimo   \n",
       "2                otimo e muito pratico 游뗵游뗵   \n",
       "3       aplicativo top, facil, e pratico.   \n",
       "4             estou adorando muito seguro   \n",
       "\n",
       "                                          pos_tagged  \n",
       "0  [(aplicativo, n), (melhorou, v), (ultimos, Non...  \n",
       "1                                    [(otimo, None)]  \n",
       "2             [(otimo, None), (pratico, v), (游뗵游뗵, n)]  \n",
       "3  [(aplicativo, n), (top, None), (,, None), (fac...  \n",
       "4                       [(adorando, v), (seguro, n)]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib as jb\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# POS tagger dictionary\n",
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "\n",
    "def token_stop_pos(text):\n",
    "    tagger = jb.load('POS_tagger_brill.pkl')\n",
    "    # tags = pos_tag(word_tokenize(text))\n",
    "    tags = tagger.tag(word_tokenize(text))\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "        if word.lower() not in set(stopwords.words('portuguese')):\n",
    "            newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "    return newlist\n",
    "\n",
    "data['pos_tagged'] = data['cleaned_reviews'].apply(token_stop_pos)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "      <th>pos_tagged</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aplicativo melhorou n칩s 칰ltimos meses.</td>\n",
       "      <td>aplicativo melhorou nos ultimos meses.</td>\n",
       "      <td>[(aplicativo, n), (melhorou, v), (ultimos, Non...</td>\n",
       "      <td>aplicativo melhorou ultimos me .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>칍timo</td>\n",
       "      <td>otimo</td>\n",
       "      <td>[(otimo, None)]</td>\n",
       "      <td>otimo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>칍timo e muito pr치tico 游뗵游뗵</td>\n",
       "      <td>otimo e muito pratico 游뗵游뗵</td>\n",
       "      <td>[(otimo, None), (pratico, v), (游뗵游뗵, n)]</td>\n",
       "      <td>otimo pratico 游뗵游뗵</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aplicativo TOP, F치cil, e Pr치tico.</td>\n",
       "      <td>aplicativo top, facil, e pratico.</td>\n",
       "      <td>[(aplicativo, n), (top, None), (,, None), (fac...</td>\n",
       "      <td>aplicativo top , facil , pratico .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>estou adorando muito seguro</td>\n",
       "      <td>estou adorando muito seguro</td>\n",
       "      <td>[(adorando, v), (seguro, n)]</td>\n",
       "      <td>adorando seguro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 comments  \\\n",
       "0  Aplicativo melhorou n칩s 칰ltimos meses.   \n",
       "1                                   칍timo   \n",
       "2                칍timo e muito pr치tico 游뗵游뗵   \n",
       "3       Aplicativo TOP, F치cil, e Pr치tico.   \n",
       "4             estou adorando muito seguro   \n",
       "\n",
       "                          cleaned_reviews  \\\n",
       "0  aplicativo melhorou nos ultimos meses.   \n",
       "1                                   otimo   \n",
       "2                otimo e muito pratico 游뗵游뗵   \n",
       "3       aplicativo top, facil, e pratico.   \n",
       "4             estou adorando muito seguro   \n",
       "\n",
       "                                          pos_tagged  \\\n",
       "0  [(aplicativo, n), (melhorou, v), (ultimos, Non...   \n",
       "1                                    [(otimo, None)]   \n",
       "2             [(otimo, None), (pratico, v), (游뗵游뗵, n)]   \n",
       "3  [(aplicativo, n), (top, None), (,, None), (fac...   \n",
       "4                       [(adorando, v), (seguro, n)]   \n",
       "\n",
       "                                  lemma  \n",
       "0      aplicativo melhorou ultimos me .  \n",
       "1                                 otimo  \n",
       "2                      otimo pratico 游뗵游뗵  \n",
       "3    aplicativo top , facil , pratico .  \n",
       "4                       adorando seguro  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "        if not pos: \n",
    "            lemma = word\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "        else:  \n",
    "            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew\n",
    "\n",
    "data['lemma'] = data['pos_tagged'].apply(lemmatize)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def translate(text):\n",
    "    return GoogleTranslator(source='auto', target='en').translate(text)\n",
    "\n",
    "data['translation'] = data['lemma'].apply(translate)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "from spacy import displacy \n",
    "import visualise_spacy_tree\n",
    "from IPython.display import Image, display\n",
    "\n",
    "nlp = spacy.load('pt_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_names(text):\n",
    "    \n",
    "    names = []\n",
    "    \n",
    "    # Create a spacy doc\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    #create the list of words to match\n",
    "    security_terms = ['segur']\n",
    "\n",
    "    #obtain doc object for each word in the list and store it in a list\n",
    "    patterns = [nlp(term) for term in security_terms]\n",
    "                \n",
    "    # Matcher class object \n",
    "    matcher = PhraseMatcher(nlp.vocab) \n",
    "    matcher.add(\"SECURITY_PATTERN\", patterns)\n",
    "\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    # Finding patterns in the text\n",
    "    for i in range(0,len(matches)):\n",
    "        \n",
    "        # match: id, start, end\n",
    "        token = doc[matches[i][1]:matches[i][2]]\n",
    "        # append token to list\n",
    "        names.append(str(token))\n",
    "            \n",
    "    return names\n",
    "\n",
    "# Apply function\n",
    "data['extraction'] = data['lemma'].apply(find_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adorando seguro\n",
      "  agio pratico seguro simplificar vida apenas alguns toque parabens ! ! ! !\n",
      "  aplicativo bastante seguro pratico . gostando\n",
      "  bom seguro !\n",
      "  bom seguro melhor podemos pagar contas sair casa\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    if len(data.loc[i,'extraction'])!=0:\n",
    "        print(data.loc[i,'lemma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Blob - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# function to calculate subjectivity \n",
    "def getSubjectivity(review):\n",
    "    return TextBlob(review).sentiment.subjectivity\n",
    "\n",
    "# function to calculate polarity\n",
    "def getPolarity(review):\n",
    "    return TextBlob(review).sentiment.polarity\n",
    "\n",
    "# function to analyze the reviews\n",
    "def analysis(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data = pd.DataFrame(data[['comments', 'translation']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data['Subjectivity'] = analysis_data['translation'].apply(getSubjectivity) \n",
    "analysis_data['Polarity'] = analysis_data['translation'].apply(getPolarity) \n",
    "analysis_data['Analysis'] = analysis_data['Polarity'].apply(analysis)\n",
    "analysis_data.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
